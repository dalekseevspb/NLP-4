{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "AlekseevDP (DSU-4, NLP-4)_HW(7)_Классификация в NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcgMmb-QuyiT"
      },
      "source": [
        "\n",
        "\n",
        "## ДЗ по лекции №7 \"Классификация в NLP\": Сделать классификацию данных fakenews\n",
        "Используя ноутбук занятия (также размещен в папке Materials) и данные fakenews, 3 раза разными способами получить на задаче классификации значение f1 выше 0.91 для методов на sklearn и выше 0.52 для методов на pytorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EQ4-xO7uyiU",
        "outputId": "7e59c1bb-e9cf-4469-dd7f-cd412775e991"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-10 16:24:08--  https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1253562 (1.2M) [text/plain]\n",
            "Saving to: ‘Constraint_Train.csv’\n",
            "\n",
            "Constraint_Train.cs 100%[===================>]   1.20M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-07-10 16:24:08 (31.2 MB/s) - ‘Constraint_Train.csv’ saved [1253562/1253562]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YCpo8FuuyiW"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NSv9Mo9X-tT"
      },
      "source": [
        "df = pd.read_csv('Constraint_Train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hgpfPhA0uyiX",
        "outputId": "74c7d80e-2418-40b5-9cc2-6ada6d032502"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              tweet label\n",
              "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
              "1   2  States reported 1121 deaths a small rise from ...  real\n",
              "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
              "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
              "4   5  Populous states can generate large case counts...  real"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73234668-04a5-4fb4-8a4f-26e6cd972f4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73234668-04a5-4fb4-8a4f-26e6cd972f4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73234668-04a5-4fb4-8a4f-26e6cd972f4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73234668-04a5-4fb4-8a4f-26e6cd972f4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QVUEiLfuyiY"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HbHy4nVNKtt",
        "outputId": "6b191283-72d2-429e-b962-cc093decb850"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO62Fv2YuyiY",
        "outputId": "aa6b1b20-1326-4ff4-d4a5-fab74e152a18"
      },
      "source": [
        "sentences = [word_tokenize(text.lower()) for text in tqdm(df.tweet)]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6420/6420 [00:01<00:00, 3413.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV6DsOOPuyiZ",
        "outputId": "1d6e8ea2-c165-4792-de23-3863f94b2eae"
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "%time model_tweets = Word2Vec(sentences, workers=4, size=300, min_count=3, window=5, iter=15)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.11 s, sys: 99.3 ms, total: 9.21 s\n",
            "Wall time: 5.37 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmqe5t6BuyiZ",
        "outputId": "c14a3596-de66-46cb-c20d-fa05c3c6aee2"
      },
      "source": [
        "model_tweets.wv.most_similar('france')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('front', 0.9463140964508057),\n",
              " ('aires', 0.9376326203346252),\n",
              " ('floor', 0.9345133304595947),\n",
              " ('protesting', 0.9301860928535461),\n",
              " ('tower', 0.9299658536911011),\n",
              " ('crying', 0.9280542731285095),\n",
              " ('deceased', 0.9249671697616577),\n",
              " ('parliament', 0.9245487451553345),\n",
              " ('buenos', 0.9210494756698608),\n",
              " ('suggesting', 0.9208232164382935)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1C2ivBwuyia"
      },
      "source": [
        "model_tweets.wv.init_sims()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gegRNK8fuyib"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aQM-6_Cuyib"
      },
      "source": [
        "def get_text_embedding(text):\n",
        "    result = []\n",
        "    for word in word_tokenize(text.lower()):\n",
        "        if word in model_tweets.wv:\n",
        "            result.append(model_tweets.wv[word])\n",
        "\n",
        "    if len(result):\n",
        "        result = np.sum(result, axis=0)\n",
        "    else:\n",
        "        result = np.zeros(300)\n",
        "    return result"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEXHIkb7uyib",
        "outputId": "92b16138-c4ca-43b6-cacf-9af1ff07b78b"
      },
      "source": [
        "features = [get_text_embedding(text) for text in tqdm(df.tweet)]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6420/6420 [00:02<00:00, 2430.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYWbsK2Duyic"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45OhRwtTuyic"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, df.label, test_size=0.33)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_JNAMZ2uyic",
        "outputId": "49bd63f9-0f56-4c48-bb2f-7b9e3a051030"
      },
      "source": [
        "model = LogisticRegression(max_iter=5000)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=5000)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrWxWWhmuyic"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSBQINBVuyid"
      },
      "source": [
        "predicted = model.predict(X_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh8xvZ-nuyid",
        "outputId": "5936cf04-a592-489e-84fd-fa7767d05792"
      },
      "source": [
        "print(classification_report(y_test, predicted))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.92      0.93      0.92      1000\n",
            "        real       0.94      0.92      0.93      1119\n",
            "\n",
            "    accuracy                           0.93      2119\n",
            "   macro avg       0.93      0.93      0.93      2119\n",
            "weighted avg       0.93      0.93      0.93      2119\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5qCQpNduyid"
      },
      "source": [
        "###  Вариант 1. Что будет, если использовать самый наивный метод (CountVectorizer)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKLUWP8huyie"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY2CQW0wuyie"
      },
      "source": [
        "vec = CountVectorizer()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7CxqeGwuyie"
      },
      "source": [
        "bow = vec.fit_transform(df.tweet)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVzRicjKuyif",
        "outputId": "e7abb85c-76c6-4944-98da-246ee0dfa8c6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(bow, df.label, test_size=0.33)\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=5000)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMowWWtnuyif",
        "outputId": "fe560bee-3ff0-4f25-bac5-6c9a0836af68"
      },
      "source": [
        "predicted = model.predict(X_test)\n",
        "print(classification_report(y_test, predicted))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.92      0.92      0.92       984\n",
            "        real       0.93      0.93      0.93      1135\n",
            "\n",
            "    accuracy                           0.92      2119\n",
            "   macro avg       0.92      0.92      0.92      2119\n",
            "weighted avg       0.92      0.92      0.92      2119\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим, что метрика f1-score несущественно ухудшилась (с 0.93 до 0.92)."
      ],
      "metadata": {
        "id": "av2MkjrlA3Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вариант 2. Попробуем векторизатор Tf-Idf с параметрами по умолчанию (разбивка только на униграммы)."
      ],
      "metadata": {
        "id": "dQ5PVq7-9YPk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYwoVRMbuyif"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "PtY8GsQd2BWU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow = tfidf.fit_transform(df.tweet)"
      ],
      "metadata": {
        "id": "dcG32T-12BP1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(bow, df.label, test_size=0.33)\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_Hvasn52BIU",
        "outputId": "bb751c35-26de-44d2-9d28-2c797df5cfac"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=5000)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(X_test)\n",
        "print(classification_report(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1Jjgpgc65yu",
        "outputId": "4dd91f8a-da8a-40da-e7de-7f4cb0f72c62"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.91      0.91      0.91      1019\n",
            "        real       0.92      0.92      0.92      1100\n",
            "\n",
            "    accuracy                           0.92      2119\n",
            "   macro avg       0.92      0.92      0.92      2119\n",
            "weighted avg       0.92      0.92      0.92      2119\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим, что метрика f1-score осталась прежней (0.92). "
      ],
      "metadata": {
        "id": "UQaM4IcgBOJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вариант 3. Теперь попробуем векторизатор Tf-Idf с разбивкой твитов на n-граммы от 1 (униграмм) до 3 (триграмм)."
      ],
      "metadata": {
        "id": "2NDZ5Ugj-UFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_ngrams = TfidfVectorizer(ngram_range = (1, 3))"
      ],
      "metadata": {
        "id": "TpYgyeVe65pe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow = tfidf_ngrams.fit_transform(df.tweet)"
      ],
      "metadata": {
        "id": "no22fgq9-tcr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(bow, df.label, test_size=0.33)\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i0GQmoT-tYw",
        "outputId": "e676f969-7274-44fe-9ac2-59f8af8c3fac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=5000)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(X_test)\n",
        "print(classification_report(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pheOpyC6-tRW",
        "outputId": "c93b3b99-4b55-4856-cb59-a9bba8331f6c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.89      0.92      0.90      1003\n",
            "        real       0.92      0.90      0.91      1116\n",
            "\n",
            "    accuracy                           0.91      2119\n",
            "   macro avg       0.91      0.91      0.91      2119\n",
            "weighted avg       0.91      0.91      0.91      2119\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На N-граммах от 1 до 3 метрика f1-score еще незначительно ухудшилась (до 0.91). \n",
        "\n",
        "Можно сделать вывод, что использование TF-Idf-векторизатора вместо самого простого CountVectorizer в данном случае не привело к повышению точности предсказаний. При этом CountVectorizer работает быстрее, чем TF-IDF (на большом датасете было бы заметно)."
      ],
      "metadata": {
        "id": "85zOwNuiBtzg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6qOclJPuyif"
      },
      "source": [
        "### Часть 2. PyTorch + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHDxqZnTuyif"
      },
      "source": [
        "labels = (df.label == 'real').astype(int).to_list()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fUz2OKauyif"
      },
      "source": [
        "Нужно заранее задать размер для максимальной длины предложений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BkQTxbMuyig"
      },
      "source": [
        "token_lists = [word_tokenize(text.lower()) for text in df.tweet]\n",
        "max_len = len(max(token_lists, key=len))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "125Q6tQhuyig",
        "outputId": "c5a4c22a-af82-4839-a241-e4bcba8a9ffb"
      },
      "source": [
        "max_len"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1592"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HUNPzqWuyig"
      },
      "source": [
        "Это слишком много. Но какая длина обычно?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQVd6Fruyig"
      },
      "source": [
        "from collections import Counter\n",
        "fd = Counter([len(tokens) for tokens in token_lists])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CycieWjbuyih",
        "outputId": "9bf5b6c6-76de-4e1c-b68a-357110dad4c3"
      },
      "source": [
        "fd.most_common(10)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(20, 178),\n",
              " (25, 174),\n",
              " (22, 170),\n",
              " (18, 170),\n",
              " (19, 168),\n",
              " (21, 168),\n",
              " (16, 163),\n",
              " (17, 162),\n",
              " (15, 160),\n",
              " (23, 156)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LNWZldVuyih"
      },
      "source": [
        "## Вариант 1. Зададим максимальную длину предложений в 200 символов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxPTNDQ0uyii"
      },
      "source": [
        "Возьмём те же w2v эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNOPWCq1uyii"
      },
      "source": [
        "def get_word_embedding(tokens, max_len):\n",
        "    result = []\n",
        "    for i in range(max_len):\n",
        "        if i < len(tokens):\n",
        "            word = tokens[i]\n",
        "            if word in model_tweets.wv:\n",
        "                result.append(model_tweets.wv[word])\n",
        "            else:\n",
        "                result.append(np.zeros(300))\n",
        "        else:\n",
        "            result.append(np.zeros(300))\n",
        "    return result"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBkyQdORuyii",
        "outputId": "87ce9b58-2ec0-4381-d822-6a13748f9fc3"
      },
      "source": [
        "features = [get_word_embedding(text, 200) for text in tqdm(token_lists)]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6420/6420 [00:03<00:00, 2055.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_COity4Puyij"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXHLD6eKuyij"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwGQpAbcuyij",
        "outputId": "56bebf35-9a95-4fea-9b38-4e04431723e3"
      },
      "source": [
        "len(features[0][0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNRDEXNRdOF",
        "outputId": "b6d66ad1-b148-4dbc-c85e-6f2501fc8d00"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4301"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVsXkUfMRlc1",
        "outputId": "541f9650-7eed-402e-82ad-04be5b8aac13"
      },
      "source": [
        "len(X_train[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZuoO5uhRpmy",
        "outputId": "5761265c-770f-42cb-eb65-eee59e39b9fd"
      },
      "source": [
        "len(X_train[0][0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-N2gN0xuyij",
        "outputId": "b6a5b6a0-89be-4445-8d85-4a16b55c9b7a"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(300, 100)\n",
        "        self.out = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings, (shortterm, longterm) = self.lstm(x.transpose(0, 1))\n",
        "        prediction = torch.sigmoid(self.out(longterm))\n",
        "        return prediction\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (lstm): LSTM(300, 100)\n",
            "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOjKyQdnuyij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cea285d-ecc9-4255-9282-b0d393a2b7ff"
      },
      "source": [
        "in_data = torch.tensor(X_train).float()\n",
        "targets = torch.tensor(y_train).float()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Surg_PcQuyij",
        "outputId": "d782de78-da96-4697-f54d-5b00d66da617"
      },
      "source": [
        "in_data.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4301, 200, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ8WQFlnuyik"
      },
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujjn4KVIuyik"
      },
      "source": [
        "def train_one_epoch(in_data, targets, batch_size=16):\n",
        "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
        "        batch_x = in_data[i:i + batch_size]\n",
        "        batch_y = targets[i:i + batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        output = net(batch_x)\n",
        "        loss = criterion(output.reshape(-1), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(loss)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CorzeZjIuyik",
        "outputId": "0c47e808-c046-48a5-be3e-315fa48b5e82"
      },
      "source": [
        "train_one_epoch(in_data, targets)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [03:17<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pna8zQLluyil"
      },
      "source": [
        "Что получилось?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQGiiAiLuyil"
      },
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VuVw4uUuyil"
      },
      "source": [
        "with torch.no_grad():\n",
        "    output = net(in_data_test).reshape(-1)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJxlSn2buyil"
      },
      "source": [
        "result = (output > 0.5) == targets_test"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTYoH6Xpuyil",
        "outputId": "e1fcdb09-ab99-4470-9acd-3c2ad6ed423b"
      },
      "source": [
        "result.sum().item() / len(result)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5219443133553563"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вариант 2. Попробуем взять максимальную длину предложений 300 (вместо 200)."
      ],
      "metadata": {
        "id": "iBEWHwikvzJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [get_word_embedding(text, 300) for text in tqdm(token_lists)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqbfOHBewSA4",
        "outputId": "f021751e-ad98-416a-d797-67599d05abbc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6420/6420 [00:04<00:00, 1549.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33)"
      ],
      "metadata": {
        "id": "ZAaiFrSPwi52"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_data = torch.tensor(X_train).float()\n",
        "targets = torch.tensor(y_train).float()"
      ],
      "metadata": {
        "id": "7mFySfbQwi0z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrTXRfsAwlJu",
        "outputId": "31e4ada4-7068-4ed9-fa2e-f1b3941b7d86"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4301, 300, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "v0IPIPL2wlEZ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(in_data, targets, batch_size=16):\n",
        "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
        "        batch_x = in_data[i:i + batch_size]\n",
        "        batch_y = targets[i:i + batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        output = net(batch_x)\n",
        "        loss = criterion(output.reshape(-1), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(loss)"
      ],
      "metadata": {
        "id": "qWHFkuE_wk_y"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_one_epoch(in_data, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5diK9tuyfq0",
        "outputId": "c5df4793-99b0-4282-8401-a914006a2fc8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [02:29<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6910, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ],
      "metadata": {
        "id": "5CPBHpBryflw"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    output = net(in_data_test).reshape(-1)"
      ],
      "metadata": {
        "id": "vl_L-T-Jzow0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = (output > 0.5) == targets_test"
      ],
      "metadata": {
        "id": "7zyH_tbtzosQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.sum().item() / len(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ior6bpAyfhZ",
        "outputId": "e80f1e27-e10d-4d76-ba27-82678e037c43"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5403492213308164"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим, что результат улучшился с 0.52 до 0.54 при использовании макс.длины предложений 300 вместо 200, но в Гугл Колаб доступная память была практически полностью использована (риск аварийного завершения среды исполнения).\n",
        "\n",
        "## Вариант 3. Попробуем использовать другой оптимизатор (Adam  вместо SGD) и другую функцию потерь (\"Mean Squared Error\" вместо \"Binary Cross Entropy\")."
      ],
      "metadata": {
        "id": "5FxUUopU0AWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "WqvwqdZwwixa"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_one_epoch(in_data, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL6gA5wI1zAI",
        "outputId": "6ae81766-31f2-44a5-8276-7a078dcb26b1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [03:19<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2491, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ],
      "metadata": {
        "id": "-UR200fS1y6d"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    output = net(in_data_test).reshape(-1)"
      ],
      "metadata": {
        "id": "r3xWsw1n1y1C"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = (output > 0.5) == targets_test"
      ],
      "metadata": {
        "id": "hzNobfIB28M8"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.sum().item() / len(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZANvsjLj276b",
        "outputId": "c483c342-506d-4f42-debd-90b7c928bad6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5403492213308164"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим, что обучение прошло чуть дольше, результат при этом остался прежним (0.54)."
      ],
      "metadata": {
        "id": "gTaifUt95FTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вариант 4. Попробуем уменьшить Learning Rate с 0.01 до 0.001. Остальные параметры модели оставим, как в варианте №3."
      ],
      "metadata": {
        "id": "sDwOTn8D5ao-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "R75aDnq_5vhc"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_one_epoch(in_data, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTF8Vnz25zK3",
        "outputId": "f48f098c-e6c7-4c9b-dd19-dfd5d79b73f7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [02:33<00:00,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2489, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ],
      "metadata": {
        "id": "TzZ8gRbw5zEZ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    output = net(in_data_test).reshape(-1)"
      ],
      "metadata": {
        "id": "o72AkP5c6L5E"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = (output > 0.5) == targets_test"
      ],
      "metadata": {
        "id": "g2ya81-Q6Lxk"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.sum().item() / len(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymbefiyq5y_4",
        "outputId": "5aa997b7-23bf-41e5-a297-3a2f53e723dd"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5403492213308164"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение прошло чуть быстрее, но результат остался прежним (0.54)."
      ],
      "metadata": {
        "id": "2ql3IwJy6iEE"
      }
    }
  ]
}